{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvuKXJ5GlMS_"
   },
   "source": [
    "# LHW 1 : Convolutional Neural Networks for text classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b36XXZRalMTA"
   },
   "source": [
    "In this homework, you will be implementing the _forward pass_, _backpropagation_, and _gradient checking_ for a convolutional neural network with sparse inputs for text classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpfUJH2xlMTB"
   },
   "source": [
    "## The setup\n",
    "Let's define parameters for the Convolutional Neural Network. You do not need to modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lTAULV7lMTB"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "#import Exception \n",
    "\n",
    "# window size for the CNN\n",
    "width = 2\n",
    "\n",
    "# number of filters\n",
    "F = 100\n",
    "\n",
    "# learning rate\n",
    "alpha = 1e-1\n",
    "\n",
    "# vocabsize: size of the total vocabulary\n",
    "vocabsize = 10000\n",
    "\n",
    "# vocab: the vocabulary dictionary with the word as key and its index as value\n",
    "# the input will be transformed into respective positional indices using the vocab dictionary\n",
    "# as the input for the forward and backward algorithm\n",
    "# e.g. if vocab = {'a': 0, 'simple': 1, 'sentence': 2} and the training data is\n",
    "# \"a simple simple sentence a\",\n",
    "# the input to the forward and backward algorithm will be [0,1,1,2,0]\n",
    "vocab = {}\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# U and V are weight vectors of the hidden layer\n",
    "# U: a matrix of weights of all inputs for the first\n",
    "# hidden layer for all F filters in the\n",
    "# where each filter has the size of vocabsize by width (window size)\n",
    "# U[i, j, k] represents the weight of filter u_j\n",
    "# for word with vocab[word] = i when the word is\n",
    "# at the position k of the sliding window\n",
    "# e.g. for the example, \"a simple simple sentence a\",\n",
    "# if the window size is 4 and we are looking at the first sliding window\n",
    "# of the 9th filter, the weight for the last \"sentence\" will be U[2, 8, 3]\n",
    "# i.e U[index of the word in vocab, index of the filter, position of the word in that sliding window]\n",
    "U = np.random.normal(loc=0, scale=0.01, size=(vocabsize, F, width))\n",
    "\n",
    "# V: the the weight vector of the F filter outputs (after max pooling)\n",
    "# that will produce the output, i.e. o = sigmoid(V*h)\n",
    "V = np.random.normal(loc=0, scale=0.01, size=(F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Odm8EscxlMTF"
   },
   "source": [
    "Let's define some utility functions that may be useful. You don't need to modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAxXagVElMTF"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    helper function that computes the sigmoid function\n",
    "    \"\"\"\n",
    "    return 1. / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "def read_vocab(filename):\n",
    "    \"\"\"\n",
    "    helper function that builds up the vocab dictionary for input transformation\n",
    "    \"\"\"\n",
    "    file = open(filename)\n",
    "    for line in file:\n",
    "        cols = line.rstrip().split(\"\\t\")\n",
    "        word = cols[0]\n",
    "        idd = int(cols[1])\n",
    "        vocab[word] = idd\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    :param filename: the name of the file\n",
    "    :return: list of tuple ([word index list], label)\n",
    "    as input for the forward and backward function\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    file = open(filename)\n",
    "    for line in file:\n",
    "        cols = line.rstrip().split(\"\\t\")\n",
    "        label = int(cols[0])\n",
    "        words = cols[1].split(\" \")\n",
    "        w_int = []\n",
    "        for w in words:\n",
    "            # skip the unknown words\n",
    "            if w in vocab:\n",
    "                w_int.append(vocab[w])\n",
    "        data.append((w_int, label))\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"\n",
    "    main caller function that reads in the names of the files\n",
    "    and train the CNN to classify movie reviews\n",
    "    \"\"\"\n",
    "    vocabFile = \"vocab.txt\"\n",
    "    trainingFile = \"movie_reviews.train\"\n",
    "    testFile = \"movie_reviews.dev\"\n",
    "\n",
    "    read_vocab(vocabFile)\n",
    "    training_data = read_data(trainingFile)\n",
    "    test_data = read_data(testFile)\n",
    "\n",
    "    for i in range(50):\n",
    "        # confusion matrix showing the accuracy of the algorithm\n",
    "        confusion_training = np.zeros((2, 2))\n",
    "        confusion_validation = np.zeros((2, 2))\n",
    "        for (data, label) in training_data:\n",
    "            backward(data, label)\n",
    "            # calculate forward and evaluate\n",
    "            prob = forward(data)[\"prob\"]\n",
    "            pred = 1 if prob > .5 else 0\n",
    "            confusion_training[pred, label] += 1\n",
    "        for (data, label) in test_data:\n",
    "            # calculate forward and evaluate\n",
    "            prob = forward(data)[\"prob\"]\n",
    "            pred = 1 if prob > .5 else 0\n",
    "            confusion_validation[pred, label] += 1\n",
    "            \n",
    "        print(\"Epoch: {}\\tTrain accuracy: {:.3f}\\tDev accuracy: {:.3f}\"\n",
    "            .format(\n",
    "            i,\n",
    "            np.sum(np.diag(confusion_training)) / np.sum(confusion_training),\n",
    "            np.sum(np.diag(confusion_validation)) / np.sum(confusion_validation)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6qRm7re6lMTI"
   },
   "source": [
    "## 1. Forward\n",
    "\n",
    "Given the parameters and definition of the CNN model (ยง2 of HW), complete the Forward Function to calculate _o_ (the probability of the positive class) for an input text. You may not import any additional libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCeZ9T2ClMTJ"
   },
   "outputs": [],
   "source": [
    "def forward(word_indices):\n",
    "    \"\"\"\n",
    "    :param word_indices: a list of word indices, i.e. idx = vocab[word]\n",
    "    :return: a result dictionary containing 3 items -\n",
    "    result['prob']: output of the CNN algorithm.\n",
    "    result['h']: the hidden layer output after max pooling, h = [h1, ..., hF]\n",
    "    result['hid']: argmax of F filters, e.g. j of x_j\n",
    "    e.g. for the ith filter u_i, tanh(word[hid[i], hid[i] + width]*u_i) = max(h_i)\n",
    "    \"\"\"\n",
    "\n",
    "    h = np.zeros(F, dtype=float) # F is the no of filters \n",
    "    hid = np.zeros(F, dtype=int)\n",
    "    prob = 0.0\n",
    "\n",
    "    # step 1. compute h and hid\n",
    "    # loop through the input data of word indices and\n",
    "    # keep track of the max filtered value h_i and its position index x_j\n",
    "    # h_i = max(tanh(weighted sum of all words in a given window)) over all windows for u_i\n",
    "    \"\"\"\n",
    "    Type your code below\n",
    "    \"\"\"\n",
    "    window_size=width\n",
    "#    c=0\n",
    "    for j in range(F):\n",
    "        pool_arr=np.zeros(len(word_indices)+window_size-1, dtype=float)\n",
    "        # Array to store the weighted averages of all windows\n",
    "        for i in range(len(word_indices)-window_size):\n",
    "            window=word_indices[i:i+window_size]\n",
    "            #print('window',window)\n",
    "            p_sum=0\n",
    "            #window is the concat operator            \n",
    "            for k in range(window_size):\n",
    "                #print(window[k],j,k)\n",
    "                p_sum+=U[window[k],j,k]\n",
    "                \n",
    "            pool_arr[i]=math.tanh(p_sum)\n",
    "        h[j]=max(pool_arr)\n",
    "        hid[j]=np.argmax(pool_arr)\n",
    "    #Once the array h is constructed calculate htranspose * V\n",
    "    dot_prod=np.dot(h.transpose(),V)\n",
    "\n",
    "    # step 2. compute probability\n",
    "    # once h and hid are computed, compute the probabiliy by sigmoid(h^TV)\n",
    "    \"\"\"\n",
    "    Type your code below\n",
    "    \"\"\"\n",
    "    prob=sigmoid(dot_prod)\n",
    "\n",
    "    # step 3. return result\n",
    "    return {\"prob\": prob, \"h\": h, \"hid\": hid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJp_ZVpjlMTL"
   },
   "source": [
    "## 2. Backward\n",
    "\n",
    "Using the gradient update equations for V (ยง3 in HW) and U (ยง3.1), implement the updates for U and V in the backward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CpH-pgHClMTM"
   },
   "outputs": [],
   "source": [
    "def backward(word_indices, true_label):\n",
    "    \"\"\"\n",
    "    :param word_indices: a list of word indices, i.e. idx = vocab[word]\n",
    "    :param true_label: true label (0, 1) of the movie reviews\n",
    "    :return: None\n",
    "    update weight matrix/vector U and V based on the loss function\n",
    "    \"\"\"\n",
    "    global U, V\n",
    "    pred = forward(word_indices)\n",
    "    prob = pred[\"prob\"]\n",
    "    h = pred[\"h\"]\n",
    "    hid = pred[\"hid\"]\n",
    "    \n",
    "    # update U and V here\n",
    "    # loss_function = y * log(o) + (1 - y) * log(1 - o)\n",
    "    #               = true_label * log(prob) + (1 - true_label) * log(1 - prob)\n",
    "    # to update V: V_new = V_current + d(loss_function)/d(V)*alpha\n",
    "    # to update U: U_new = U_current + d(loss_function)/d(U)*alpha\n",
    "    # Make sure you only update the appropriate argmax term for U\n",
    "    \"\"\"\n",
    "    Type your code below\n",
    "    \"\"\"\n",
    "    for j in range(len(h)):\n",
    "        log_loss_gradient_v = (true_label - prob)*h[j]\n",
    "        #print('old value of V',V[j])\n",
    "        V[j]=V[j]+log_loss_gradient_v*alpha\n",
    "        \n",
    "        #print('new value of V',V[j])\n",
    "        x_i=word_indices[hid[j]:hid[j]+width]\n",
    "        #print(x_i)  \n",
    "        p_sum=0\n",
    "        for i in range(width):\n",
    "            p_sum+=U[x_i[i],j,i]\n",
    "        #storing the value of tanh of the weighted average\n",
    "        tan_xu=math.tanh(p_sum)\n",
    "        for i in range(width):\n",
    "            log_loss_gradient_u_i = (true_label - prob)*(1-(tan_xu*tan_xu))*V[j]\n",
    "            #print('old value of U',U[x_i[i],j,i])\n",
    "            U[x_i[i],j,i]+=log_loss_gradient_u_i*alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "e9HxI0Mxifnh",
    "outputId": "ffaa5149-c625-452f-846f-898e217130c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain accuracy: 0.999\tDev accuracy: 0.532\n",
      "Epoch: 1\tTrain accuracy: 0.998\tDev accuracy: 0.576\n",
      "Epoch: 2\tTrain accuracy: 0.999\tDev accuracy: 0.578\n",
      "Epoch: 3\tTrain accuracy: 1.000\tDev accuracy: 0.562\n",
      "Epoch: 4\tTrain accuracy: 1.000\tDev accuracy: 0.608\n",
      "Epoch: 5\tTrain accuracy: 1.000\tDev accuracy: 0.546\n",
      "Epoch: 6\tTrain accuracy: 1.000\tDev accuracy: 0.664\n",
      "Epoch: 7\tTrain accuracy: 1.000\tDev accuracy: 0.662\n",
      "Epoch: 8\tTrain accuracy: 1.000\tDev accuracy: 0.730\n",
      "Epoch: 9\tTrain accuracy: 1.000\tDev accuracy: 0.626\n",
      "Epoch: 10\tTrain accuracy: 1.000\tDev accuracy: 0.758\n",
      "Epoch: 11\tTrain accuracy: 1.000\tDev accuracy: 0.736\n",
      "Epoch: 12\tTrain accuracy: 1.000\tDev accuracy: 0.768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c14040070a88>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# calculate forward and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prob\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mconfusion_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-f6a12b39d8c8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(word_indices)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;31m#print(window[k],j,k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                   \u001b[0mp_sum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FRFqe9IlMTO"
   },
   "source": [
    "## 3. Gradient Checking\n",
    "\n",
    "Now that you have implemented the forward and backward function, you are going to check the correctness of the implementation by calculating numerical gradients and comparing them with the analytical values. Refer to ยง4 in HW.\n",
    "\n",
    "Implement the functions that calculate numerical gradients for V and U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2-bHXLTlMTQ"
   },
   "outputs": [],
   "source": [
    "def get_log_likelyhood(y,v,h):\n",
    "    return (y*math.log(sigmoid(h*v)))+(1-y)*(math.log(1-sigmoid(h*v)))\n",
    "\n",
    "\n",
    "def calc_numerical_gradients_V(V, word_indices, true_label):\n",
    "    \"\"\"\n",
    "    :param true_label: true label of the data\n",
    "    :param V: weight vector of V\n",
    "    :param word_indices: a list of word indices, i.e. idx = vocab[word]\n",
    "    :return V_grad:\n",
    "    V_grad =    a vector of size length(V) where V_grad[i] is the numerical\n",
    "                gradient approximation of V[i]\n",
    "    \"\"\"\n",
    "    pred = forward(word_indices)\n",
    "    prob = pred[\"prob\"]\n",
    "    h = pred[\"h\"]\n",
    "    hid = pred[\"hid\"]\n",
    "    # you might find the following variables useful\n",
    "    x = word_indices\n",
    "    y = true_label\n",
    "    eps = 1e-4\n",
    "    V_grad = np.zeros(F, dtype=float)\n",
    "    for i in range(len(V)):\n",
    "        V_grad[i]=(get_log_likelyhood(y,V[i]+eps,h[i])-get_log_likelyhood(y,V[i]-eps,h[i]))/(2*eps)\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Type your code below\n",
    "    \"\"\"\n",
    "\n",
    "    return V_grad\n",
    "\n",
    "\n",
    "def calc_numerical_gradients_U(U, word_indices, true_label):\n",
    "    \"\"\"\n",
    "    :param U: weight matrix of U\n",
    "    :param word_indices: a list of word indices, i.e. idx = vocab[word]\n",
    "    :param true_label: true label of the data\n",
    "    :return U_grad:\n",
    "    U_grad =    a matrix of dimension F*width where U_grad[i, j] is the numerical\n",
    "                approximation of the gradient for the argmax of\n",
    "                each filter i at offset position j\n",
    "    \"\"\"\n",
    "    # you might find the following variables useful\n",
    "    pred = forward(word_indices)\n",
    "    prob = pred[\"prob\"]\n",
    "    h = pred[\"h\"]\n",
    "    hid = pred[\"hid\"]\n",
    "    # you might find the following variables useful\n",
    "    x = word_indices\n",
    "    y = true_label\n",
    "    eps = 1e-4\n",
    "    global V\n",
    "    U_grad = np.zeros((F, width))\n",
    "    for j in range(F):\n",
    "        window=x[hid[j]:hid[j]+width]            \n",
    "        #print('window',window)            \n",
    "        u_p_1=0 # u_p_1 stores the value of u1+eps\n",
    "        u_m_1=0 # u_m_1 stores the value of u1-eps\n",
    "        u_m_2=0 # u_m_2 stores the value of u2-eps\n",
    "        u_p_2=0 # u_p_2 stores the value of u2+eps\n",
    "        \n",
    "        u_p_1=window[0]*(U[window[0],j,0]+eps)+window[1]*U[window[1],j,1]\n",
    "        u_m_1=window[0]*(U[window[0],j,0]-eps)+window[1]*U[window[1],j,1]\n",
    "        u_p_2=window[0]*(U[window[0],j,0])+window[1]*(U[window[1],j,1]+eps)\n",
    "        u_m_2=window[0]*(U[window[0],j,0])+window[1]*(U[window[1],j,1]-eps)\n",
    "        dJ_theta_p_1=(true_label*(math.log(sigmoid(V[j]*math.tanh(u_p_1)))))+(1-true_label)*math.log(1-(sigmoid(V[j]*math.tanh(u_p_1))))\n",
    "        #dJ_theta_p_1 = J(theta+eps) for u1\n",
    "        \n",
    "        dJ_theta_m_1=(true_label*(math.log(sigmoid(V[j]*math.tanh(u_m_1)))))+(1-true_label)*math.log(1-(sigmoid(V[j]*math.tanh(u_m_1))))\n",
    "        #dJ_theta_m_1 = J(theta-eps) for u1\n",
    "        \n",
    "        U_grad[j,0]=(dJ_theta_p_1-dJ_theta_m_1)/(2*eps)\n",
    "        \n",
    "        dJ_theta_p_2=(true_label*(math.log(sigmoid(V[j]*math.tanh(u_p_2)))))+(1-true_label)*math.log(1-(sigmoid(V[j]*math.tanh(u_p_2))))\n",
    "        #dJ_theta_p_1 = J(theta+eps) for u2        \n",
    "        \n",
    "        dJ_theta_m_2=(true_label*(math.log(sigmoid(V[j]*math.tanh(u_m_2)))))+(1-true_label)*math.log(1-(sigmoid(V[j]*math.tanh(u_m_2))))\n",
    "        #dJ_theta_p_1 = J(theta-eps) for u2\n",
    "        \n",
    "        U_grad[j,1]=(dJ_theta_p_2-dJ_theta_m_2)/(2*eps)                \n",
    "    \"\"\"\n",
    "    Type your code below\n",
    "    \"\"\"\n",
    "\n",
    "    return U_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "20kQ48hIlMTT"
   },
   "source": [
    "Now that we have functions to calculate gradients, implement the check function to compare the numerical gradients with their respective analytical values. Be sure to update the analytical and numerical gradients below using the functions we wrote above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDGlNXLClMTT"
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_gradient():\n",
    "    \"\"\"\n",
    "    :return (diff in V, diff in U)\n",
    "    Calculate numerical gradient approximations for U, V and\n",
    "    compare them with the analytical values\n",
    "    check gradient accuracy; for more details, cf.\n",
    "    http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization\n",
    "    \"\"\"\n",
    "    global U,V\n",
    "    eps = 1e-4\n",
    "    x = []\n",
    "    for i in range(100):\n",
    "        x.append(np.random.randint(vocabsize))\n",
    "    y = 1\n",
    "    u_grad_a=np.zeros((F,width),dtype=float)\n",
    "    pred = forward(x)\n",
    "    prob = pred[\"prob\"]\n",
    "    h = pred[\"h\"]\n",
    "    hid = pred[\"hid\"]\n",
    "    #create an array to store the analytical gradient\n",
    "    v_grad_a=np.zeros(F,dtype=float)\n",
    "    for i in range(len(V)):\n",
    "        v_grad_a[i]=y*(1-sigmoid(h[i]*V[i]))*h[i]\n",
    "    v_grad_n=calc_numerical_gradients_V(V,x,1)\n",
    "    sum_V_diff=0\n",
    "    \n",
    "    # looping through v_grad_n and v_grad_a \n",
    "    for i in range(len(v_grad_n)):      \n",
    "        sum_V_diff+=(v_grad_n[i]-v_grad_a[i])**2\n",
    "      #adding the square of the difference to sum_V_diff\n",
    "\n",
    "    for j in range(F):\n",
    "        p_sum=0\n",
    "        window=x[hid[j]:hid[j]+width]\n",
    "        for k in range(width):        \n",
    "            p_sum+=window[k]*U[window[k],j,k]\n",
    "        for k in range(width):\n",
    "            u_grad_a[j,k]=y*(1-sigmoid(V[j]*math.tanh(p_sum)))*V[j]*window[k]*(1-(math.tanh(p_sum)**2))\n",
    "              \n",
    "    u_grad_n=calc_numerical_gradients_U(U,x,1)\n",
    "    sum_U_diff = 0\n",
    "    \n",
    "    # looping through u_grad_n and u_grad_a \n",
    "    for j in range(F):\n",
    "        for k in range(width):\n",
    "            sum_U_diff+= (u_grad_a[j,k]-u_grad_n[j,k])**2\n",
    "        #adding the square of the difference to sum_U_diff    \n",
    "        \n",
    "    print('u',sum_U_diff)\n",
    "    print('v',sum_V_diff)\n",
    "    \"\"\"\n",
    "    Update 0s below with your calculations\n",
    "    \"\"\"\n",
    "    # check V\n",
    "#     # compute analytical and numerical gradients and compare their differences\n",
    "#     ana_grad_V = 0.0 # <-- Update\n",
    "#     numerical_grad_V = 0.0 # <-- Update\n",
    "#     #sum_V_diff = sum((numerical_grad_V - ana_grad_V) ** 2)\n",
    "\n",
    "#     # check U\n",
    "#     # compute analytical and numerical gradients and compare their differences\n",
    "#     ana_grad_U = 0.0 # <-- Update\n",
    "#     numerical_grad_U = 0.0 # <-- Update\n",
    "#     sum_U_diff = sum(sum((numerical_grad_U - ana_grad_U) ** 2))\n",
    "\n",
    "    print(\"V difference: {:.8f}, U difference: {:.8f} (these should be close to 0)\"\n",
    "          .format(sum_V_diff, sum_U_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VV08m3qzlMTW"
   },
   "source": [
    "## Result\n",
    "Let's check the difference between the numerical gradients and the analytical gradients using the function completed above. Report the numbers in the writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Aeqcfg5XlMTX",
    "outputId": "4a5aaa12-d265-4e29-b414-97b58d4e11a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u 3.2949999732201257e-08\n",
      "v 4.535973502339937e-23\n",
      "V difference: 0.00000000, U difference: 0.00000003 (these should be close to 0)\n"
     ]
    }
   ],
   "source": [
    "check_gradient()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of LHW1_CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
